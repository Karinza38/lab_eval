[metadata]
name = lab_eval
version = 0.0.5
author = Daniel Migault
author_email=mglt.biz@gmail.com
description = "A package to evaluate python3 scripts submitted by students"
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/mglt/lab_eval
project_urls =
    Bug Tracker = https://github.com/mglt/lab_eval/issues
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent


[options]
package_dir = 
  = src
packages = find:
python_requires = >=3.8

[options.packages.find]
where = src

[options.entry_points]
console_scripts =
    lab_eval_lab = lab_eval.eval_lab:cli 
    lab_eval_class = lab_eval.eval_class:lab_eval_class
    lab_finalize_grades = lab_eval.eval_class:lab_finalize_grades
    lab_add_score_list = lab_eval.eval_class:lab_add_score_list
#    lab_export_xls = lab_eval.eval_class:lab_export_xls 
#    lab_moodle_to_score_list = lab_eval.eval_class:moodle_json_to_score_list
    grade_to_genote = lab_eval.moodle_file:grade_to_genote
##    lab_eval_class


